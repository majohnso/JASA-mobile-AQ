---
title: "README"
output: rmarkdown::github_document
---

## Data Files

#### oakland_data_simulated.csv
  - Contains simulated Oakland Air Quality data
  - Variables include:
    - Date_Time
    - Car_Identifier
    - Latitude
    - Longitude
    - Car_Speed
    - NO2
    
#### Data_IDs.csv
  - Contains 30m road segment IDs
  - Variables include:
    - Longitude
    - Latitude
    - ID
    
#### Data_Covariates.csv
  - Contains spatial covariate data
  - Variables include:
    - ID
    - Long30m
    - Lat30m
    - Hwy_Roads
    - Major_Roads             
    - Res_Roads               
    - Local_Trucks           
    - Local_Restricted_Trucks
    - Commerical.Zone         
    - Industrial.Zone         
    - Residential.Zone       
    - NDVI_50                 
    - NLCD_Water_50           
    - NLCD_DevOpen_50         
    - NLCD_DevLow_50         
    - NLCD_DevMed_50          
    - NLCD_DevHigh_50         
    - NLCD_Barren_50          
    - NLCD_Deciduous_50      
    - NLCD_Evergreen_50      
    - NLCD_MixForest_50       
    - NLCD_Shrub_50           
    - NLCD_Herbaceous_50     
    - NLCD_Pasture_50         
    - NLCD_Crops_50          
    - NLCD_WoodyWet_50        
    - NLCD_EmergWet_50       
    - Impervious_50         
    - Distance_to_NPL         
    - Distance_to_Rail        
    - Elevation_50        
    - Distance_to_TRI        
    - Total_Road_50         
    - Hwy_Road_50            
    - Maj_Road_50            
    - Res_Road_50             
    - Pop_50                  
    - MinDist2Port           
    - MinDist2MainPort       
    - Dist2MainAirport        
    - Dist2Airport     

## R/C++ Files

  <tt> Rfunctions_GC.R </tt>
  
  - contains all R functions to perform estimation and prediction for the STx, ST and S models
    
  <tt> cpp_code_GC.cpp </tt>
  
  - contains helper c++ files to speed up estimation and prediction
  
  <tt> run_all_code.R </tt> 
  
  - <tt> R </tt> script to perform analysis included in the paper on simulated data provided in the Data folder
  - Calls the follwing helper scripts
    - <tt> data_setup.R </tt>
        - cleans up raw data and performs temporal aggregation at 15 sec and 1 min block medians
        - each aggregated dataset is saved and stored in <tt> data_blockmed.Rda </tt>
    - <tt> st_stx_estimation_prediction.R </tt>
        - performs parameter estimation and prediction for the ST and STx models
        - results are stored as <tt> R </tt> objects and saved out in <tt> .Rda </tt> files
    - <tt> spatial_only_estimation_prediciton.R </tt>
        - performs parameter estimation and prediction for the S (spatial only) model
        - results are stored as <tt> R </tt> objects and saved out in <tt> .Rda </tt> files
    - <tt> 15min_map_forecasts.R </tt>
        - creates 15 min ahead spatial map forecasts for the ST model for two days
        - used to recreate maps contained in Figures 5 and 6 of the paper
    - <tt> rolling_window_estimation.R </tt>
        - performs ST and STx model estimation on data in 21-week rolling windows
        - results are stored in <tt> .Rda </tt> files
    - <tt> deployment_design.R </tt>
        - performs the simulation experiment comparing mspe for mobile vs fixed-location monitors 
        
<tt> plotting_code.R </tt>

  - Contains code to construct the plots include in the paper after obtaining all results from <tt>run_all_code.R</tt>
 


## Reproducing the analysis on simulated data

The R script <tt> run_all_code.R </tt> illustrates the analysis performed in ``Fine-scale spatiotemporal air pollution analysis using mobile monitors on Google Street View vehicles" using simulated data. The simulated data included here is meant to help understand how the following code can be used, but any interested user should obtain the actual data from Google. The data is freely available upon request from [here](https://docs.google.com/forms/d/e/1FAIpQLSf_4GIkK1tmVMFRSxz42KgvOM3Z3NGeOFFje_FS8FBbz1vTig/viewform). Using the real data, the <tt> run_all_code.R </tt> should recreate the analysis included in the paper. 

The following sections walk through the various components of <tt> run_all_code.R </tt>.

### Set Parameters
```{r setup_params, eval=FALSE}

rolling_window = FALSE # should rolling window estimation be performed? (computationally expensive)

type <- 2; # type in 1:3, defines which data product to use 
# 1 == raw data, 2 == 15sec aggregates, 3 == 1min aggregates

j <- 3 # j in 1:4, which estimation lag, index of h <- c(0.02, 5, 15, 60) min
jj <- 3 # jj in 1:3, which size of conditioning set, index of m <- c(10, 30, 60) min

lag <- 21 # lag for moving window 

if(type==1){
  ns <- 100 # if using 1sec data, define the size to subsample the conditioning set in Vecchia
  nsA <- 800 # if using 1sec data, define the nearest neighbor size for Car A prediction
}

nnbs <- 800 # number of nearest neighbors for spatial only prediction

maxit <- 1e3 # maximum number of iterations for Nelder-Mead maximization of Vecchia log-likelihood
```

### Load R Packages

```{r packages, eval=FALSE}
pkg.names <- c("Rcpp", "RcppArmadillo", "doParallel", "RANN", "chron", "fields", 
               "dplyr", "FNN", "ggplot2", "ggmap")

for(i in 1:length(pkg.names)){
  if(pkg.names[i] %in% rownames(installed.packages()) == FALSE) {
    install.packages(pkg.names[i])
    cat("\r", pkg.names[i])
  }
}

lp <- sapply(pkg.names, require, character.only = TRUE)

if(sum(lp)!=length(pkg.names)){
  stop(paste0("Unable to load packages: ", paste(pkg.names[!lp], collapse = ", ")))
}
```

### Source R Functions
```{r functions, eval=FALSE}
source("Rfunctions_GC.R")
sourceCpp("cpp_code_GC.cpp")
```

### Process Raw Data and Perform Temporal Aggregation

```{r agg, eval=FALSE}
source("data_setup.R")
# Necessary files loaded in data_setup.R:
# Data_IDs.csv # road segment ID
# Data_Covariates.csv #GIS covariates
# oakland_data_simulated.csv # simulated Google car dataset
#
# Saves out temporally aggregated datasets in "data_blockmed.Rda"
```

### Model Fitting Setup
```{r fitting, eval=FALSE}
########### Set Up Data For Model Fitting ##########
h <- c(0.02, 5, 15, 60) # minutes
m <- c(10, 30, 60) # minutes 


load("data_blockmed.Rda")
df$Y_block_med <- df$Y
df$Car = ifelse(df$Car=="Car_B",2,1)

covar = c("Longitude","Latitude","t",paste0("PC",1:7))

if(type == 1) df_block = df
if(type == 2) df_block = df_block_tseg15sec
if(type == 3) df_block = df_block_tseg1min

keep = c("Y_block_med","locID","Longitude","Latitude","Car","speed","year",
         "month","day","hour","min","sec","wday","t",paste0("PC",1:7),paste0("H",1:4))
df_block[,colnames(df_block)%in%paste0("PC",1:7)] = scale(df_block[,colnames(df_block)%in%paste0("PC",1:7)])
df_block=df_block[order(df_block$t),keep]

regressorname = c()
foo = paste0("(",paste0("PC",1:7,collapse ="+"),")")
for(i in 1:4) regressorname = c(regressorname,paste0("H",i,"*",foo))

PCidx <- which(colnames(df_block)%in%c(paste0("PC",1:7),paste0("H",1:4)))
cov_names <- c(paste0("PC",1:7),paste0("H",1:4))

days = sort(unique(floor(df_block$t)))
df_block$day = floor(df_block$t)

if(rolling_window){
  #  create blocks of two weeks
  wk_block = seq(192,max(days),by = 7*1)
  daysint = findInterval(df_block$day, wk_block)
  df_block$daysint = daysint; 
  df_block$idx = 1:nrow(df_block);
}
```

### Fit Models

```{r models, eval=FALSE}
source("st_stx_estimation_prediction.R") 
# NOTE: this estimation can take several hours to run, depending on the number of cores used
```
ST and STx Vecchia estimation and prediction for <tt>type</tt>, and combination of <tt>h</tt> (<tt>j</tt>) and <tt>m</tt> (<tt>jj</tt>) specified above. Saves out estimated parameters; 5min, 15min and 60min forecasts; Car A predictions; mspe and correlation in <tt>.Rda</tt> files.

```{r smodel, eval=FALSE}
source("spatial_only_estimation_prediction.R")
# NOTE: this can take several hours to run, depending on the number of cores used.
```

S model Vecchia approximation estimation and prediction for <tt>type</tt>, and combination of <tt>h</tt> (<tt>j</tt>) and <tt>m</tt> (<tt>jj</tt>) specified above. Saves out estimated parameters, spatial predictions, Car A predictions, mspe and correlation in <tt>.Rda</tt> files

```{r rw, eval=FALSE}
if(rolling_window){
  source("rolling_window_estimation.R")
}
```
ST and STx Vecchia estimation and prediction using rolling windows with window size lag = 21 weeks.
For example, data from week 1-21 are used for parameter estimation, then prediction is made for week 22. This procedure is then repeated for the next window of week 2-22. The rolling window analysis to compare ST and STx Vecchia models is performed in parallel for each window in practice. It is not performed here by default (<tt>rolling_window = FALSE</tt>) because the example simulated data spans only two months. The results are saved out for each window in <tt>.Rda</tt> files

### Map Forecasts
```{r maps, eval=FALSE}
# run for dayidx = 253 and dayidx = 490 
if(type == 2){
  for(dayidx in c(253, 490)){
    source("15min_map_forecasts.R")
  }
}
```
Creates full spatial 15-min ahead map forecasts for the two different days and times included in the paper (Figures 5 and 6).

### Mobile vs. Stationary Simulation
```{r deployment, eval=FALSE}
source("deployment_design.R")

# NOTE: this can take several hours to run, depending on the number of cores used.
```

Performs a simulation experiment comparing mean squared prediction error (MSPE) for mobile vs fixed-location monitors for short-term forecasting and spatial interpolation. For <tt>ncar=1,...,15</tt> and <tt>nstation=1,...,15</tt>, we sample <tt>ncar</tt> number of routes from the Google data and randomly select <tt>nstation</tt> number of locations in the study region as fixed-location monitors. The MSPE is computed for both type of monitors conditional on locations from ncar and nstation of monitors respectively. This procedure is repeated 30 times to obtain uncertainty of the MSPE.

